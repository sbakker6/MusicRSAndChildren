{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52e8c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from properties import LYRICS_ROOT_FOLDER, LFM2B_DB\n",
    "from pathlib import Path\n",
    "from fuzzywuzzy import fuzz\n",
    "from datetime import datetime\n",
    "import sqlite3\n",
    "import logging\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "\n",
    "class ExtractionResults:\n",
    "    def __init__(self, parts: list[str], failed: list[str]):\n",
    "        self.parts : list[str] = parts   # for example [\"Intro\", \"Pre-Chorus\", \"Chorus\", ...]\n",
    "        self.failed : list[str] = failed # any failures are recorded here\n",
    "\n",
    "class Song:\n",
    "    ID = 0\n",
    "    def __init__(self, title, artist, lyrics):\n",
    "        self.id = Song.ID\n",
    "        Song.ID += 1\n",
    "        self.title : str = title\n",
    "        self.artist : str = artist\n",
    "        self.lyrics : str = lyrics\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.artist} - {self.title}\"\n",
    "    \n",
    "    def extract_structure(self, structure_strategy) -> ExtractionResults :\n",
    "        return structure_strategy(self.lyrics)\n",
    "\n",
    "SONG_PROCESSING_FOLDER = LYRICS_ROOT_FOLDER / \"extraction\"\n",
    "\n",
    "CATEGORIES = set(\n",
    "    [\n",
    "        \"Intro\",\n",
    "        \"Chorus\",\n",
    "        \"Pre-Chorus\",\n",
    "        \"Post-Chorus\",\n",
    "        \"Refrain\",\n",
    "        \"Bridge\",\n",
    "        \"Verse\",\n",
    "        \"Outro\",\n",
    "        \"Interlude\",\n",
    "        \"Hook\",\n",
    "        \"Pre-Hook\",\n",
    "        \"Post-Hook\",\n",
    "        \"Post Hook\",\n",
    "        \"Break\",\n",
    "        \"Couplet\",\n",
    "        \"Piano Solo\",\n",
    "        \"Guitar Solo\",\n",
    "        \"Verso\",\n",
    "        \"Pre-Coro\",\n",
    "        \"Pont\",\n",
    "        \"Instrumental\",\n",
    "        \"Zwrotka\", # Verse in Polish,\n",
    "        \"Refren\", # Refrain in polish,\n",
    "        \"Куплет\", # Verse in Russian/Bulgarian...\n",
    "        \"Strofa\", #Verse in Italian,\n",
    "        \"Vamp\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# If the brackets satisfy any of these predicates, then they will be marked ignored (\"-\")\n",
    "IGNORES = [\n",
    "    lambda x: x.lower().startswith(\"produced by\")\n",
    "]\n",
    "\n",
    "def map_to_category(text: str) -> str:\n",
    "    if any([ignore_predicate(text) for ignore_predicate in IGNORES]):\n",
    "        return \"-\"\n",
    "\n",
    "    low = text.lower()\n",
    "    contenders = [cat for cat in CATEGORIES if cat.lower() in low]\n",
    "    if not any(contenders):\n",
    "        return None\n",
    "    \n",
    "    return sorted(contenders, key=len, reverse=True)[0] # longest contender wins\n",
    "\n",
    "def find_all_brackets(lyrics: str):\n",
    "    return re.findall(r\"\\[.*\\]\", lyrics)                    # ['[Intro: foo]', '[Verse 1]', ...]\n",
    "\n",
    "\n",
    "OPENING_CHAR, CLOSING_CHAR = (\"[\", \"]\")\n",
    "\n",
    "def validate_brackets(lyrics: str):\n",
    "    stack = 0\n",
    "    for i, char in enumerate(lyrics):\n",
    "        if char == OPENING_CHAR:\n",
    "            stack += 1\n",
    "\n",
    "        if char == CLOSING_CHAR:\n",
    "            stack -= 1\n",
    "\n",
    "    if stack != 0:\n",
    "        raise ValueError(\"Invalid brackets\")\n",
    "\n",
    "def find_all_brackets_manually(lyrics: str):\n",
    "    validate_brackets(lyrics)\n",
    "    brackets = []\n",
    "    i = 0\n",
    "    while i < len(lyrics):\n",
    "        if lyrics[i] != OPENING_CHAR:\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        j = i\n",
    "        while lyrics[j] != CLOSING_CHAR:\n",
    "            j += 1\n",
    "        brackets.append(lyrics[i:j+1])\n",
    "        i = j\n",
    "    return brackets\n",
    "\n",
    "def structure_extraction_strat1(lyrics: str) -> ExtractionResults:\n",
    "    brackets = find_all_brackets_manually(lyrics)\n",
    "    brackets_content = list(map(lambda b: b[1:-1], brackets))   # ['Intro: foo'  , 'Verse 1', ...]\n",
    "    parts = list(map(map_to_category, brackets_content))\n",
    "    failures = []\n",
    "    for i, part in enumerate(parts):\n",
    "        if part is None:\n",
    "            failures.append(brackets_content[i])\n",
    "    return ExtractionResults(parts, failures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617afee7",
   "metadata": {},
   "source": [
    "# 1. Parse lyrics.jl with help of artist_info.json\n",
    "\n",
    "In the lyrics.jl file, each line looks like this \n",
    "\n",
    "```json\n",
    "{\"song\": \"Kendrick-lamar-swimming-pools-drank-lyrics\", \"lyrics\": \" ... \"}\n",
    "```\n",
    "\n",
    "We want to parse the song name as provided in this file into (1) artist and (2) song title.\n",
    "\n",
    "In artist_info.json, we have \n",
    "```json\n",
    "{\n",
    "  \"url_name\": \"Kendrick-lamar\",\n",
    "  \"followers\": 23782,\n",
    "  \"roles\": [\n",
    "    \"Verified Artist\",\n",
    "    \"Contributor\"\n",
    "  ],\n",
    "  \"iq\": 39144,\n",
    "  \"songs\": [\n",
    "    \"Kendrick-lamar-humble-lyrics\",\n",
    "    \"A-ap-rocky-fuckin-problems-lyrics\",\n",
    "    \"Kendrick-lamar-maad-city-lyrics\",\n",
    "    \"Kendrick-lamar-swimming-pools-drank-lyrics\",\n",
    "    \"...\"\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "So ideally, we want to recognize that the artist of the song is \"Kendrick Lamar\", and the song title is \"Humble\". And we can do so by crossreferencing lyrics.jl with artist_info.json.\n",
    "\n",
    "Another strategy is that, of the songs of which this mapping fails, we extract the longest common prefix from the song url (the \"song\" attribute of lyrics.jl) and we can then say with some confidence that this will be the artist name, since we know that the url starts with the artist name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb422077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infered song data for 37351 songs\n",
      "Failed for 97 due to artist mapping not found\n",
      "Disregarded 545 entries (annotations)\n"
     ]
    }
   ],
   "source": [
    "artist_names : list[str] = [] # listing all the distinct artist names from artist_info \n",
    "with open(Path(LYRICS_ROOT_FOLDER, \"artist_info.json\"), 'r') as artist_info:\n",
    "    while (line := artist_info.readline()):\n",
    "        data = json.loads(line)\n",
    "        artist = data['url_name']\n",
    "\n",
    "        if artist in artist_names:\n",
    "            continue\n",
    "    \n",
    "        artist_names.append(artist)\n",
    "\n",
    "\n",
    "# buckets of artist name per first char (lowercase)\n",
    "# buckets are sorted lengthwise (longest first) to make greedy artist name matching faster\n",
    "first_chars = set(map(lambda name: name[0].lower(), artist_names))\n",
    "processed_artist_names = {first_char : sorted([artist_name for artist_name in artist_names if artist_name.lower().startswith(first_char)], key=len, reverse=True) for first_char in first_chars}\n",
    "\n",
    "def find_first(pred, iterable):\n",
    "    \"\"\" Find first element of the iterable satisfying the predicate. If no match is found, returns None\"\"\"\n",
    "    for e in iterable:\n",
    "        if pred(e):\n",
    "            return e\n",
    "    return None\n",
    "\n",
    "# Now we crossreference lyrics.jl lines with these artists to the best of our ability\n",
    "songs : list[Song] = []\n",
    "not_found_artists : list[str] = []\n",
    "disregarded_songs : list[str] = []\n",
    "\n",
    "with open(Path(LYRICS_ROOT_FOLDER, \"lyrics.jl\"), 'r') as lyrics:\n",
    "    while (line := lyrics.readline()):\n",
    "        data = json.loads(line)\n",
    "        _song_info = data['song']\n",
    "\n",
    "        # There are also \"annotations\" in the lyrics.jl file but we're not interested in them.\n",
    "        if not _song_info.endswith('lyrics'): \n",
    "            disregarded_songs.append(_song_info)\n",
    "            continue\n",
    "\n",
    "        # infer the artist name by taking a look whether there is an exact match with one of the artists in the appropriate bucket\n",
    "        artist_bucket_to_search = processed_artist_names[_song_info[0].lower()]\n",
    "        matched_artist = find_first(lambda artist_name: _song_info.startswith(artist_name), artist_bucket_to_search)\n",
    "\n",
    "        if matched_artist is None:\n",
    "            not_found_artists.append(_song_info)\n",
    "            continue\n",
    "\n",
    "        # extract song title from the song info (given that we now know the artist name):\n",
    "        # example: \" \".join('artist-name-this-is-the-song-title-lyrics'.split('artist-name')[1].split('-')[1:-1]).strip() -> \"this is the song title\"\n",
    "        title = \" \".join(_song_info.split(matched_artist)[1].split('-')[1:-1]).strip()\n",
    "        songs.append(Song(title, matched_artist.replace('-', \" \").strip(), data['lyrics']))\n",
    "\n",
    "print(f\"Infered song data for {len(songs)} songs\")\n",
    "if len(not_found_artists) > 0:\n",
    "    print(f\"Failed for {len(not_found_artists)} due to artist mapping not found\")\n",
    "assert len(list(filter(lambda info: not info.endswith('annotated'), disregarded_songs))) == 0, \"All disregarded songs should be annotations\"\n",
    "if len(disregarded_songs) > 0:\n",
    "    print(f\"Disregarded {len(disregarded_songs)} entries (annotations)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79cccdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t Caye-easy-lyrics\n",
      "\t Trav-fuck-and-smoke-lyrics\n",
      "\t Amil-4-da-fam-lyrics\n",
      "\t B-smyth-leggo-lyrics\n",
      "\t Chevralet-ss-bad-mother-fucker-bmf-lyrics\n",
      "\t Cb4-straight-outta-locash-lyrics\n",
      "\t Terra-g-clock-work-lyrics\n",
      "\t Quincy-exotic-lyrics\n",
      "\t Quin-over-again-lyrics\n",
      "\t Koryn-hawthorne-bright-fire-lyrics\n",
      "\t Acid-drop-king-im-a-problem-lyrics\n",
      "\t Kda-just-say-lyrics\n",
      "\t Trey-smith-find-you-somewhere-lyrics\n",
      "\t Bwa-ron-all-i-ever-wanted-lyrics\n",
      "\t Ambre-preach-lyrics\n",
      "\t Artistes-divers-vald-sofiane-kalash-criminel-biffty-et-suikon-blaze-ad-en-live-dans-planete-rap-lyrics\n",
      "\t Catch-lungs-gotta-kill-this-lyrics\n",
      "\t Fedy-only-thing-i-know-lyrics\n",
      "\t Batgang-dangerous-lyrics\n",
      "\t Tamia-officially-missing-you-midi-mafia-mix-with-rap-lyrics\n",
      "\t Kold-i-love-the-holy-grail-lyrics\n",
      "\t Tamar-braxton-the-one-lyrics\n",
      "\t Tracey-lee-keep-your-hands-high-lyrics\n",
      "\t Cashflow-harlem-want-my-love-back-lyrics\n",
      "\t A1billionaire-rookie-of-the-year-lyrics\n",
      "\t Louis-mattrs-oops-x-wus-good-lyrics\n",
      "\t T-la-rock-and-jazzy-jay-its-yours-lyrics\n",
      "\t Bando-jonez-sex-you-remix-lyrics\n",
      "\t 1wayfrank-make-it-happen-lyrics\n",
      "\t Teamcakee-post-to-be-cake-mix-lyrics\n",
      "\t Amy-schumer-milk-milk-lemonade-lyrics\n",
      "\t L-devine-peer-pressure-lyrics\n",
      "\t Ar-side-god-lyrics\n",
      "\t Vell-oakland-lyrics\n",
      "\t Cdot-honcho-02-shit-remix-lyrics\n",
      "\t Fekky-way-too-much-lyrics\n",
      "\t Ar15-cant-see-me-again-lyrics\n",
      "116\n",
      "\t 116-now-they-know-lyrics\n",
      "\t 116-man-up-anthem-lyrics\n",
      "\t 116-light-work-lyrics\n",
      "\t 116-come-alive-lyrics\n",
      "\t 116-authority-lyrics\n",
      "\t 116-repentance-lyrics\n",
      "\t 116-and-parris-chariz-big-wave-lyrics\n",
      "\t 116-temptation-lyrics\n",
      "\t 116-envy-lyrics\n",
      "Air every needs\n",
      "\t Air-every-needs-heaven-scent-lyrics\n",
      "\t Air-every-needs-bullet-lyrics\n",
      "Bankroll mafia\n",
      "\t Bankroll-mafia-out-my-face-lyrics\n",
      "\t Bankroll-mafia-hyenas-lyrics\n",
      "\t Bankroll-mafia-bankrolls-on-deck-lyrics\n",
      "\t Bankroll-mafia-i-want-her-lyrics\n",
      "\t Bankroll-mafia-smoke-tree-lyrics\n",
      "\t Bankroll-mafia-neg-4-degrees-lyrics\n",
      "Bruno mars\n",
      "\t Bruno-mars-just-the-way-you-are-remix-lyrics\n",
      "\t Bruno-mars-gorilla-g-mix-lyrics\n",
      "\t Bruno-mars-the-other-side-lyrics\n",
      "\t Bruno-mars-liquor-store-blues-lyrics\n",
      "\t Bruno-mars-money-make-her-smile-lyrics\n",
      "Bruno mars thats what i like\n",
      "\t Bruno-mars-thats-what-i-like-gucci-mane-remix-lyrics\n",
      "\t Bruno-mars-thats-what-i-like-partynextdoor-remix-lyrics\n",
      "Cash cash\n",
      "\t Cash-cash-devil-lyrics\n",
      "\t Cash-cash-take-me-home-lyrics\n",
      "Cashmere cat\n",
      "\t Cashmere-cat-wild-love-lyrics\n",
      "\t Cashmere-cat-europa-pools-demo-lyrics\n",
      "\t Cashmere-cat-throw-myself-a-party-lyrics\n",
      "\t Cashmere-cat-quit-lyrics\n",
      "\t Cashmere-cat-adore-lyrics\n",
      "\t Cashmere-cat-night-night-lyrics\n",
      "\t Cashmere-cat-trust-nobody-lyrics\n",
      "\t Cashmere-cat-love-incredible-lyrics\n",
      "\t Cashmere-cat-infinite-stripes-lyrics\n",
      "Cast of mary poppins returns\n",
      "\t Cast-of-mary-poppins-returns-nowhere-to-go-but-up-lyrics\n",
      "\t Cast-of-mary-poppins-returns-the-royal-doulton-music-hall-lyrics\n",
      "Cham\n",
      "\t Cham-boom-boom-lyrics\n",
      "\t Cham-ghetto-story-lyrics\n",
      "Ekali babylon\n",
      "\t Ekali-babylon-lyrics\n",
      "\t Ekali-babylon-skrillex-and-ronny-j-remix-lyrics\n",
      "Ester dean\n",
      "\t Ester-dean-drop-it-low-remix-lyrics\n",
      "\t Ester-dean-rio-rio-lyrics\n",
      "K\n",
      "\t K-upreme-no-deal-lyrics\n",
      "\t K-check-on-me-lyrics\n",
      "Kirblagoop\n",
      "\t Kirblagoop-i-cant-feel-my-face-lyrics\n",
      "\t Kirblagoop-cocaina-pearls-lyrics\n",
      "\t Kirblagoop-man-down-lyrics\n",
      "Kirk franklin\n",
      "\t Kirk-franklin-123-victory-remix-lyrics\n",
      "\t Kirk-franklin-lean-on-me-lyrics\n",
      "Lil\n",
      "\t Lil-krystalll-tic-tac-demo-lyrics\n",
      "\t Lil-silva-right-for-you-lyrics\n",
      "Lil wyte\n",
      "\t Lil-wyte-oxy-cotton-lyrics\n",
      "\t Lil-wyte-fucked-up-lyrics\n",
      "Tear da club up thugs\n",
      "\t Tear-da-club-up-thugs-hypnotize-cash-money-lyrics\n",
      "\t Tear-da-club-up-thugs-slob-on-my-knob-lyrics\n",
      "Vladimir cauchemar\n",
      "\t Vladimir-cauchemar-aulos-reloaded-lyrics\n",
      "\t Vladimir-cauchemar-elevation-lyrics\n",
      "Added 58 new songs\n"
     ]
    }
   ],
   "source": [
    "# Strategy to infer new arists names: extract the longest common prefix of the  song (that will be the artist probably)\n",
    "\n",
    "# 1. bucket per first char again to make the process easier (again, also sorted by length -- largest first)\n",
    "not_found_first_chars = set(map(lambda name: name[0].lower(), not_found_artists))\n",
    "not_found_artists_bucketed = {first_char : sorted([artist_name for artist_name in not_found_artists if artist_name.lower().startswith(first_char)], key=len, reverse=True) for first_char in not_found_first_chars}\n",
    "artist_still_not_found : list[str] = []\n",
    "\n",
    "matches = {}\n",
    "extracted_artists = set()\n",
    "\n",
    "for info in not_found_artists:\n",
    "\n",
    "    # Maybe we have already processed the artist\n",
    "    match = find_first(lambda x: info.replace('-', \" \").strip().startswith(x), sorted(extracted_artists, key=len, reverse=True))\n",
    "    if match is not None:\n",
    "        matches[info] = match\n",
    "        continue\n",
    "    \n",
    "    bucket_longest_first = sorted(not_found_artists_bucketed[info.lower()[0]], key=len, reverse=True)\n",
    "    \n",
    "    bucket_size = len(bucket_longest_first)\n",
    "    # We cannot leverage other songs to guess the artist, because this is the only one in there\n",
    "    if bucket_size == 1:\n",
    "        artist_still_not_found.append(info)\n",
    "        continue\n",
    "\n",
    "    # Check matches with others and assign a confidence score (percentage)\n",
    "    others = bucket_longest_first\n",
    "    others.remove(info)\n",
    "    others_ranked = {other : 0 for other in others}\n",
    "    for other in others:\n",
    "        word_pairs = zip(info.split('-'), other.split('-'))\n",
    "        for info_word, other_word in word_pairs:\n",
    "            if info_word != other_word:\n",
    "                break\n",
    "            others_ranked[other] += 1\n",
    "            \n",
    "    ## Now we sort by ranked and see how much they have in common\n",
    "    largest_common_prefix_word_count = max(others_ranked.values())\n",
    "    others_matching = list(filter(lambda x: others_ranked[x] == largest_common_prefix_word_count, others))\n",
    "    # Now we assign the artist to these songs\n",
    "    resolved_artist_name = \" \".join(info.split('-')[:largest_common_prefix_word_count]).strip()\n",
    "    matches[info] = resolved_artist_name\n",
    "# Show the found artists\n",
    "reversed_matches = {}\n",
    "for song, artist in matches.items():\n",
    "    if artist not in reversed_matches.keys():\n",
    "        reversed_matches[artist] = []\n",
    "    reversed_matches[artist].append(song)\n",
    "\n",
    "for artist in sorted(reversed_matches.keys()):\n",
    "    print(artist)\n",
    "    for song in reversed_matches[artist]:\n",
    "        print('\\t', song)\n",
    "\n",
    "new_songs : list[Song] = []\n",
    "# Update the data with the custom found\n",
    "with open(Path(LYRICS_ROOT_FOLDER, \"lyrics.jl\"), 'r') as lyrics:\n",
    "    while (line := lyrics.readline()):\n",
    "        data = json.loads(line)\n",
    "        song_info = data['song']\n",
    "        if song_info not in matches.keys() or matches[song_info] == '':\n",
    "            continue\n",
    "        artist = matches[song_info]\n",
    "        title = \" \".join(song_info.split(artist.replace(\" \", \"-\"))[1].split('-')[1:-1]).strip()\n",
    "        new_songs.append(Song(title, artist.replace('-', \" \").strip(), data['lyrics']))\n",
    "\n",
    "print(f\"Added {len(new_songs)} new songs\")\n",
    "all_songs = songs + new_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888e5cc6",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- Check how many songs are left without artists \n",
    "- Check the artists\n",
    "    - Bruno Mars\n",
    "- Check the labels (other languages?)\n",
    "- Check label generation (greedy does not work, we need the first occurence)\n",
    "    - Section repeat indicators (\"\\[Hook\\] -2X\" in Da ruckus - We shine)\n",
    "    - Some songs have \"illegal\" or excessive brackets in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7c5df68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the songs to a csv file:\n",
    "with open(Path(SONG_PROCESSING_FOLDER, \"lyrics_tracks.tsv\"), 'w') as f:\n",
    "    writer = csv.writer(f, delimiter=\"\\t\")\n",
    "    writer.writerow([\"track_id\", \"artist_name\", \"track_name\"])\n",
    "    for song in all_songs:\n",
    "        writer.writerow([song.id, song.artist, song.title])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35305aff",
   "metadata": {},
   "source": [
    "# 2. Crossreference the data\n",
    "## How to link the LFM2B dataset to this extracted data?\n",
    "\n",
    "We have extracted song artists and titles for which we have the lyrics available from lyrics.jl.\n",
    "These are now neatly written to a tsv file where each song also has an ID. \n",
    "\n",
    "So, the idea is to create a new file in which we link tracks by their ID in the LFM2B dataset and their ID in the genius lyrics dataset. \n",
    "\n",
    "The matching process is inherently inprecise, as tracks might not all be represented in the same way in both datasets. \n",
    "Therefore, we do \"fuzzy matching\" per song on both the artist as well as the track name. \n",
    "\n",
    "So each song from the genius lyrics database (GLDB) matches to zero or more artists in LFM2B and to zero or more track names in LFM2B. \n",
    "\n",
    "Then we will assign a confidence score for the artist and for the track name using a fuzzy matching library `fuzzywuzzy`. This yields a score \\[0-100\\] (percentage overlap; capitalization ignored).\n",
    "\n",
    "We simply rank the matches on their score (highest score = rank 1).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "485dcf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary table where we only consider the tracks where we could have lyrics (non-instrumental)\n",
    "\n",
    "con = sqlite3.connect(LFM2B_DB)\n",
    "cursor = con.cursor()\n",
    "# Note: track_no_instrumental in LFM2B created with query\n",
    "# cursor.execute(f\"CREATE TEMPORARY TABLE non_instrumental_songs AS SELECT * FROM track NATURAL JOIN track_no_instrumental\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "267ce134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Had 0 errors\n",
      "Last song id None\n"
     ]
    }
   ],
   "source": [
    "class LFM2BMatch:\n",
    "    def __init__(\n",
    "        self,\n",
    "        song,\n",
    "        lfm2b_artist_id,\n",
    "        lfm2b_artist_name,\n",
    "        artist_confidence,\n",
    "        lfm2b_track_id,\n",
    "        lfm2b_track_name,\n",
    "        track_confidence,\n",
    "    ):\n",
    "        self.song = song\n",
    "        self.lfm2b_artist_id =lfm2b_artist_id\n",
    "        self.lfm2b_artist_name = lfm2b_artist_name\n",
    "        self.lfm2b_track_id = lfm2b_track_id\n",
    "        self.lfm2b_track_name = lfm2b_track_name\n",
    "        self.artist_confidence = artist_confidence\n",
    "        self.track_confidence = track_confidence\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.lfm2b_artist_name} - {self.lfm2b_track_name}\"\n",
    "\n",
    "\n",
    "matches: list[LFM2BMatch] = []\n",
    "non_matched: list[Song] = []\n",
    "errors : list[tuple[Song, Exception]] = []\n",
    "\n",
    "# We need to remove the handler so that the logs will not be written to the cell's output. \n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%dT%H_%M_%S\")\n",
    "MAPPING_LOG_PATH = Path(LYRICS_ROOT_FOLDER, f\"lfm2b-genius-mapping_{timestamp}.log\")\n",
    "logging.basicConfig(\n",
    "    filename=MAPPING_LOG_PATH,\n",
    "    level=logging.INFO,\n",
    "    datefmt=\"%d-%m-%Y,%H:%M:%S\",\n",
    "    format=\"%(levelname)s - %(asctime)s: %(message)s\",\n",
    "    encoding=\"utf8\",\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "\n",
    "def similarity_score(a: str, b: str) -> int:\n",
    "    \"\"\"Return a score [0-100] on how similar `a` is to `b`\"\"\"\n",
    "    return fuzz.ratio(a.lower(), b.lower())\n",
    "\n",
    "\n",
    "def find_best_track_match(song: Song, artists: list, tracks: list, write_function) -> LFM2BMatch | None:\n",
    "    \"\"\" Extracts the best match according to the procedure descibred in the above cell. \n",
    "    Given a song (GLDB), matched artists (LFM2B) and matched tracks (LFM2B), ranks the matches and returns the best ranked match if possible. \n",
    "    If no artists are matched in the first place, then no match can be made, so `None` is returned.\n",
    "    \n",
    "    Matches are directly written with the `write_function` and the process is logged to file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the ranking \n",
    "\n",
    "    artist_name_ranking = []\n",
    "    for artist_id, artist_name in artists:\n",
    "        artist_name_ranking.append((song.artist, artist_id, artist_name, similarity_score(song.artist, artist_name)))\n",
    "\n",
    "    track_name_ranking = []\n",
    "    for track_id, track_name, artist_id, artist_name in tracks:\n",
    "        track_name_ranking.append((song.title, track_id, track_name, artist_id, artist_name, similarity_score(song.title, track_name)))\n",
    "\n",
    "    artist_name_ranking.sort(key=lambda x: x[3], reverse=True)\n",
    "    track_name_ranking.sort(key=lambda x: x[5], reverse=True)\n",
    "\n",
    "    LIMIT = 10 # limit the amount of logged rankings for file size purposes\n",
    "    logger.info(\"\\t artist ranking\")\n",
    "    for artist_ranking in artist_name_ranking[:LIMIT]:\n",
    "        logger.info(\"\\t\\t %s\", artist_ranking)\n",
    "\n",
    "    logger.info(\"\\t track ranking\")\n",
    "    for track_ranking in track_name_ranking[:LIMIT]:\n",
    "        logger.info(\"\\t\\t %s\", track_ranking)\n",
    "\n",
    "    logger.info(\"\\t verdict\")\n",
    "\n",
    "    best_match: LFM2BMatch | None = None  # We assume no match (for example if there are no eligible tracks)\n",
    "\n",
    "    # Ideally, we have the best ranked track (name) with the highest best ranked artist name\n",
    "    if len(track_name_ranking) > 0 and len(artist_name_ranking) > 0:\n",
    "        for ranked_track in track_name_ranking:\n",
    "            for ranked_artist in artist_name_ranking:\n",
    "                if ranked_track[3] == ranked_artist[1]:\n",
    "                    best_match = LFM2BMatch(\n",
    "                        song,\n",
    "                        lfm2b_artist_id=ranked_artist[1],\n",
    "                        lfm2b_artist_name=ranked_artist[2],\n",
    "                        artist_confidence=ranked_artist[-1],\n",
    "                        lfm2b_track_id=ranked_track[1],\n",
    "                        lfm2b_track_name=ranked_track[2],\n",
    "                        track_confidence=ranked_track[-1],\n",
    "                    )\n",
    "                    break\n",
    "    elif len(track_name_ranking) > 0:\n",
    "        best_ranked_track = track_ranking[0]\n",
    "        # We have only track information, so just get the best track\n",
    "        best_match = LFM2BMatch(\n",
    "            song,\n",
    "            lfm2b_artist_id=best_ranked_track[3],\n",
    "            lfm2b_artist_name=best_ranked_track[4],\n",
    "            artist_confidence=0,\n",
    "            lfm2b_track_id=best_ranked_track[1],\n",
    "            lfm2b_track_name=best_ranked_track[2],\n",
    "            track_confidence=best_ranked_track[-1],\n",
    "        )\n",
    "\n",
    "    logger.info(\"\\t\\t %s\", best_match)\n",
    "    write_function(best_match) # write the match to file, note that an exception will be raised when there is no match found (None). This is caught in the error logfile on purpose. \n",
    "\n",
    "\n",
    "# Here we define bounds for the matching process \n",
    "# It is a very long process, so it is nice to be able to split it up into chuncks\n",
    "START_SONG_ID = 0\n",
    "END_SONG_ID = 0\n",
    "last_song_id = None\n",
    "\n",
    "def do_song_mapping():\n",
    "    \"\"\" This is the process of mapping the songs. It is made into a function purely because it can then be easily commented out after all processing is done.\"\"\"\n",
    "    global last_song_id\n",
    "    with open(f\"errors_{START_SONG_ID}-{END_SONG_ID}.tsv\", \"w\") as error_file:\n",
    "        error_file.write(\"track_id\\ttrack\\terror\\n\")\n",
    "        with open(Path(LYRICS_ROOT_FOLDER, f\"lfm2b_genius_track_mapping_{START_SONG_ID}-{END_SONG_ID}.tsv\"), \"w\", encoding=\"utf8\") as f:\n",
    "            writer = csv.writer(f, delimiter=\"\\t\")\n",
    "            writer.writerow([\"lfm2b_track_id\", \"genius_lyrics_track_id\", \"artist_confidence\", \"track_confidence\"])\n",
    "            write_function = lambda match : writer.writerow([match.lfm2b_track_id, match.song.id, match.artist_confidence, match.track_confidence])\n",
    "            for song in all_songs:\n",
    "                try:\n",
    "                    if song.id < START_SONG_ID:\n",
    "                        continue\n",
    "                    if song.id > END_SONG_ID:\n",
    "                        break\n",
    "\n",
    "                    last_song_id = song.id\n",
    "                    logger.info(\"Computing match for song %d: %s - %s\", song.id, song.artist, song.title)\n",
    "\n",
    "                    if song.title.strip() == \"\" or song.artist.strip() == \"\":\n",
    "                        logger.info(\"\\tSkipping due to empty title or artist\")\n",
    "                        raise RuntimeError(\"Empty song artist or title\") # To collect this in the error_file, we raise exception\n",
    "                \n",
    "                    cursor.execute(f\"SELECT artist_id, artist_name FROM artist WHERE artist_name LIKE '%{song.artist}%'\")\n",
    "                    artists = cursor.fetchall()\n",
    "                    cursor.execute(f\"SELECT track_id, track_name, artist_id, artist_name FROM non_instrumental_songs NATURAL JOIN artist WHERE track_name LIKE '%{song.title}%'\")\n",
    "                    tracks = cursor.fetchall()\n",
    "\n",
    "                    if len(tracks) == 0:\n",
    "                        logger.warning(\"\\t No matches for this track, skipping...\")\n",
    "                    \n",
    "                    _ = find_best_track_match(song, artists, tracks, write_function)\n",
    "                except Exception as e:\n",
    "                    error_file.write(f\"{song.id}\\t{song}\\t{e}\\n\")\n",
    "                    errors.append((song, e))    \n",
    "\n",
    "# do_song_mapping()\n",
    "con.close()\n",
    "\n",
    "print(f\"Had {len(errors)} errors\")\n",
    "print(f\"Last song id {last_song_id}\") # Useful for monitoring the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989e93d5",
   "metadata": {},
   "source": [
    "## Fixing failed mappings\n",
    "\n",
    "To see which tracks failed, we categorize them:\n",
    "\n",
    "1. Loop through all the \"error\" csv files and group on 'error' column\n",
    "2. Loop trough all the track mappings and see whether the mappings are valid (integer keys for example)\n",
    "\n",
    "We collect those songs for which the mapping failed and we go through them again, maybe by hand.\n",
    "It might be 2000 songs tho, so we can create a streamlined CLI to accept suggestions or overrule them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22e9666e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string index out of range: 322\n",
      "'NoneType' object has no attribute 'lfm2b_track_id': 3658\n",
      ": 2\n",
      "Empty song artist or title: 13\n"
     ]
    }
   ],
   "source": [
    "error_files = list(filter(lambda fn : bool(re.match(r\"errors_\\d+-\\d+.tsv\", fn)), os.listdir(SONG_PROCESSING_FOLDER)))\n",
    "error_files.sort(key=lambda fname: int(fname[7:-4].split('-')[0]))\n",
    "\n",
    "errors = {}\n",
    "for error_file in error_files:\n",
    "    with open(SONG_PROCESSING_FOLDER / error_file, \"r\") as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        next(reader) # skip headers\n",
    "        for line in reader:\n",
    "            if line == []:\n",
    "                continue\n",
    "            track_id, _, err = line\n",
    "            if err not in errors.keys():\n",
    "                errors[err] = []\n",
    "            errors[err].append(track_id)\n",
    "\n",
    "for err, song_ids in errors.items():\n",
    "    print(f\"{err}: {len(song_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56f42f3",
   "metadata": {},
   "source": [
    "# 3. Extracting structure of the lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b86250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# failed_due_to_mismatched_brackets = []\n",
    "\n",
    "# with open(\"lyrics-failure-log\", 'w', encoding='utf8') as f:\n",
    "#     written = set()\n",
    "#     for song in all_songs:\n",
    "#         try:\n",
    "#             extraction_result = song.extract_structure(structure_strategy=structure_extraction_strat1)\n",
    "#             for fail in extraction_result.failed:\n",
    "#                 if fail in written:\n",
    "#                     continue\n",
    "#                 f.write(fail + \"\\n\")\n",
    "#                 written.add(fail)\n",
    "#         except ValueError as e:\n",
    "#             print(f\"Failed to extract song structure due to mismatched brackets for song {song}\")\n",
    "#             failed_due_to_mismatched_brackets.append(song)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "532d1c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell was for fixing earlier style error files, which did not yet contain song ids. \n",
    "\n",
    "# import os\n",
    "# error_files_to_process = list(filter(lambda filename: any(map(lambda start_val : bool(re.match(f\"errors_{start_val}-\\d+.tsv\", error_files_to_process[0])), ['3000', '7682', '12000', '12400', '12800', '13600'])), os.listdir()))\n",
    "# print(error_files_to_process)\n",
    "# error_files_to_process.sort(key=lambda fname: int(fname[7:-4].split('-')[0]))\n",
    "\n",
    "\n",
    "# all_songs = songs + new_songs\n",
    "# for filename in error_files_to_process:\n",
    "#     start, end = filename[7:-4].split('-')\n",
    "#     songs_to_consider = all_songs[int(start):int(end)+1]\n",
    "#     assert songs_to_consider[0].id == int(start), 'incorrect start'\n",
    "#     assert songs_to_consider[-1].id == int(end), 'incorrect end'\n",
    "#     song_index = 0\n",
    "#     with open(filename, \"r\") as original:\n",
    "#         reader = csv.reader(original, delimiter='\\t')\n",
    "#         next(reader) # header\n",
    "#         with open(filename[:-4] + \"_fixed.tsv\", \"w\") as new:\n",
    "#             writer = csv.writer(new, delimiter='\\t')\n",
    "#             writer.writerow([\"track_id\", \"track\", \"error\"])\n",
    "#             for (track, error) in reader:\n",
    "#                 while True:\n",
    "#                     curr_song = all_songs[song_index]\n",
    "#                     if track == repr(curr_song):\n",
    "#                         writer.writerow([curr_song.id, track, error])\n",
    "#                         break\n",
    "#                     song_index += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
